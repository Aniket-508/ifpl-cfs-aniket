# ============================================================================
# Shankh.ai - Environment Configuration
# ============================================================================
# Copy this file to .env and fill in your actual API keys and configuration
# Never commit .env to version control!
# ============================================================================

# ============================================================================
# GENERAL SETTINGS
# ============================================================================
NODE_ENV=development
PORT=4000

# ============================================================================
# CORS CONFIGURATION
# ============================================================================
# Frontend URL for CORS (comma-separated for multiple origins)
CORS_ORIGIN=http://localhost:5173,http://localhost:3000

# ============================================================================
# RAG SERVICE CONFIGURATION
# ============================================================================
RAG_SERVICE_URL=http://localhost:8000

# PDF and Index Paths (used by RAG service)
PDF_DIRECTORY=./data/pdfs
FAISS_INDEX_PATH=./data/faiss_index/faiss_index.bin
METADATA_PATH=./data/faiss_index/metadata.pkl

# Embedding Configuration
EMBEDDING_MODEL=paraphrase-multilingual-mpnet-base-v2
CHUNK_SIZE=700
OVERLAP=100
TOP_K_DEFAULT=5

# Whisper Transcription (optional, requires Whisper model download)
ENABLE_WHISPER_TRANSCRIPTION=false
WHISPER_MODEL_SIZE=base

# ============================================================================
# LLM PROVIDER CONFIGURATION
# ============================================================================
# Primary LLM provider: claude, openrouter, gemini, or deepseek
LLM_PROVIDER=claude

# --- Claude (Anthropic) ---
# Get your key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-api03-...
CLAUDE_MODEL=claude-sonnet-4-20250514
CLAUDE_MAX_TOKENS=4096

# --- OpenRouter ---
# Get your key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-v1-...
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet
OPENROUTER_SITE_URL=https://yoursite.com
OPENROUTER_APP_NAME=Shankh.ai

# --- Google Gemini ---
# Get your key from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=AIzaSy...
GEMINI_MODEL=gemini-1.5-pro-latest

# --- DeepSeek ---
# Get your key from: https://platform.deepseek.com/
DEEPSEEK_API_KEY=sk-...
DEEPSEEK_MODEL=deepseek-chat
DEEPSEEK_BASE_URL=https://api.deepseek.com

# LLM Fallback Chain (comma-separated, in order of preference)
LLM_FALLBACK_PROVIDERS=claude,openrouter,gemini,deepseek

# LLM Temperature and Behavior
LLM_TEMPERATURE=0.7
LLM_SYSTEM_PROMPT_OVERRIDE=

# ============================================================================
# SPEECH-TO-TEXT (STT) CONFIGURATION
# ============================================================================
# Primary STT provider: whisper, google, or azure
STT_PROVIDER=whisper

# --- OpenAI Whisper API ---
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-proj-...
WHISPER_MODEL=whisper-1

# --- Google Cloud Speech-to-Text ---
# Set up service account: https://cloud.google.com/speech-to-text/docs/before-you-begin
GOOGLE_APPLICATION_CREDENTIALS=./credentials/google-service-account.json
GOOGLE_CLOUD_PROJECT_ID=your-project-id

# --- Azure Speech Services ---
# Get your key from: https://portal.azure.com/
AZURE_SPEECH_KEY=your-azure-speech-key
AZURE_SPEECH_REGION=eastus

# STT Confidence Threshold (0.0 to 1.0)
STT_CONFIDENCE_THRESHOLD=0.7

# ============================================================================
# TEXT-TO-SPEECH (TTS) CONFIGURATION
# ============================================================================
# Primary TTS provider: gtts, azure, or elevenlabs
TTS_PROVIDER=gtts

# --- Google TTS (gTTS) - Free, no API key needed ---
GTTS_LANG_EN=en
GTTS_LANG_HI=hi
GTTS_CHUNK_SIZE=900

# --- Azure Speech Services TTS ---
AZURE_TTS_KEY=your-azure-tts-key
AZURE_TTS_REGION=eastus
AZURE_VOICE_EN=en-US-JennyNeural
AZURE_VOICE_HI=hi-IN-SwaraNeural

# --- ElevenLabs ---
# Get your key from: https://elevenlabs.io/
ELEVENLABS_API_KEY=your-elevenlabs-api-key
ELEVENLABS_VOICE_ID=21m00Tcm4TlvDq8ikWAM
ELEVENLABS_MODEL_ID=eleven_multilingual_v2

# ============================================================================
# SESSION MANAGEMENT
# ============================================================================
# Session timeout in milliseconds (default: 1 hour)
SESSION_TIMEOUT=3600000

# Enable Redis for distributed session storage (optional)
ENABLE_REDIS=false
REDIS_URL=redis://localhost:6379

# Redis Configuration (if ENABLE_REDIS=true)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# ============================================================================
# FILE UPLOAD & STORAGE
# ============================================================================
# Max audio file size in MB
MAX_AUDIO_SIZE_MB=10

# Upload directory
UPLOAD_DIR=./uploads

# Audio output directory
AUDIO_OUTPUT_DIR=./audio

# Audio cleanup interval (milliseconds, default: 1 hour)
AUDIO_CLEANUP_INTERVAL=3600000

# Max age for audio files before cleanup (milliseconds, default: 24 hours)
AUDIO_MAX_AGE=86400000

# ============================================================================
# FRONTEND CONFIGURATION
# ============================================================================
# API and WebSocket URLs (used by frontend)
VITE_API_URL=http://localhost:4000
VITE_WS_URL=ws://localhost:4000

# Frontend App Name
VITE_APP_NAME=Shankh.ai

# ============================================================================
# LOGGING & MONITORING
# ============================================================================
# Log level: debug, info, warn, error
LOG_LEVEL=info

# Enable request logging
ENABLE_REQUEST_LOGGING=true

# Enable performance monitoring
ENABLE_PERFORMANCE_MONITORING=false

# ============================================================================
# SECURITY
# ============================================================================
# Rate limiting (requests per minute per IP)
RATE_LIMIT_WINDOW_MS=60000
RATE_LIMIT_MAX_REQUESTS=100

# Enable HTTPS (for production)
ENABLE_HTTPS=false
SSL_CERT_PATH=./certs/cert.pem
SSL_KEY_PATH=./certs/key.pem

# ============================================================================
# FEATURE FLAGS
# ============================================================================
# Enable specific features
ENABLE_VOICE_INPUT=true
ENABLE_VOICE_OUTPUT=true
ENABLE_RAG_CITATIONS=true
ENABLE_FOLLOW_UP_QUESTIONS=true
ENABLE_HTML_FORMATTING=true

# ============================================================================
# DEVELOPMENT & DEBUGGING
# ============================================================================
# Enable debug mode (verbose logging)
DEBUG=false

# Mock external APIs (for testing without real API keys)
MOCK_LLM_API=false
MOCK_STT_API=false
MOCK_TTS_API=false

# Skip API key validation (not recommended for production)
SKIP_API_KEY_VALIDATION=false

# ============================================================================
# DOCKER-SPECIFIC (for docker-compose.yml)
# ============================================================================
# These are automatically set by docker-compose, but you can override them

# Service URLs (internal Docker network)
# RAG_SERVICE_URL=http://rag_service:8000
# REDIS_URL=redis://redis:6379

# ============================================================================
# NOTES
# ============================================================================
# 1. At minimum, set ONE LLM provider API key (ANTHROPIC_API_KEY recommended)
# 2. For voice input, set OPENAI_API_KEY for Whisper API (or use local Whisper)
# 3. For voice output, gTTS is free and works without API keys
# 4. Place your PDF files in ./data/pdfs/ before running ingestion
# 5. Run ingestion: cd packages/rag_service && python ingest.py
# 6. Start services: npm run dev (development) or docker-compose up (production)
#
# For detailed setup instructions, see README.md
# ============================================================================
